# Microdata

The Metadata Editor makes use of the Data Documentation Initiative (DDI) metadata standard for the documentation of microdata. The DDI version implemented in the Metadata Editor v1.0 is the DDI Codebook, version 2.5.

![image](https://user-images.githubusercontent.com/35276300/216786555-8217b6ef-7f9c-43c7-9c31-ba1c20b6249b.png)

## The DDI Codebook metadata standard

The DDI Codebook metadata standard is developed and maintained by the DDI Alliance. It contains the following main sections:
- **Document description**: contains a small number of elements used to document the metadata (not the data) 
- **Study description**: contains all elements related to document the study (survey, census or other) itself, including the title, producers, geographic and temporal coverage, sampling, etc.
- **File description**: contains a few elements used to provide information on each data file composing the dataset.
- **Variable description**: contains elements used to describe in detail each variable in the dataset. This includes variable names and labels, value labels, literal questions and interviewer instructions, summary statistics, and more. This section of the DDI Codebook provides a detailed data dictionary.
- **Variable groups**: contains elements to organize the variables by groups (other than the data file they belong to). This section is optional.

For documenting microdata, the Metadata Editor also makes use of the Dublin Core metadata standard to document **external resources**. External resources are electronic files or links that provide content other than the metadata stored in the DDI. This may consist of PDF questionnaires or manuals, data processing scripts, images or videos, or any other resource related to the dataset that is available in a digital format.

## Preparing your data and documentation

Before you start documentating a dataset, it is highly recommended to organize your files in a convenient manner, and to properly check your data. The Metadata Editor is not a data editor; it assumes that the data being documented have been organized and edited prior to being documented. We provide here a few suggestions and recommendations fir quality controls. The quality of the output generated by the Metadata Editor will in part depend upon this preparatory and verification work. 

### Gathering and organizing the files

**Organize your files in folders**

A study may contain a large number of files: data files, manuals, questionnaires and other documents, scripts, tables, images, and others. The documentation of a dataset will be most efficient if you organize these files properly. We recommend that, before anything else, you create these resources in a standardized directory structure where resources are organized by type. The main folder could be named using the unique identifier for the study. SUb-folders can be created to store the data files (possibly in different versions), the documentation, the analytical output, etc. The Metadata Editor does not impose any structure, but it is recommended to adopt a standardized structure for all your datasets. This could for example be as follows:

![image](https://user-images.githubusercontent.com/35276300/215342948-57ad26a3-db23-435c-aa4c-73a6a2867539.png)

IMPORTANT NOTE: 
When documenting a dataset, some changes may be made to the files. You will select the data files to be included in the package, you may drop some variables from the data files, and you may edit the variable names, labels, and the value labels. Make sure you **always preserve an unaltered version of all resources**. Create a copy of the resources, and work on this new version, leaving the original files untouched. If you made a mistake, no information will be lost.

### If you already have a DDI file

Some data capture software application can export metadata in DDI. DDI will contain variable-level metadata, not study level. CsPro and Survey Solutions. In such case, you will import the metadata already available. See ...

### Run quality checks

Prior to documenting a micro-dataset, ensure that you are working with the most appropriate version. If the dataset is meant for public release, you should work with the final, edited, anonymous version of the dataset. If the dataset is being documented for archiving and internal use only, you may want include the raw data as well as the final, fully edited files. You may in some cases document separately multiple versions of a same dataset.

Once the files have been selected and properly organized in folders and sub-folders, run a series of checks and balances prior to start documenting the study. Listed below are some commonly-encountered quality issues: 

- Absence of variables that uniquely identify each record of the dataset ("keys"), duplicated observations, and errors from merging multiple data files.
- Incomplete data (missing variables and/or missing observations) when comparing the content of the data files with the original survey questionnaire or sample design.
- Unlabelled variables and values.
- Variables with unexplained missing values.
- Temporary ("junk") variables found in the data files.
- Data with sensitive information or direct identifiers present in data files intended for dissemination.

To minimize such issues, the following procedures are recommended for preparing your data files:

1. Organize your data in a hierarchical format 

It is preferable to organize your files in a hierarchical format instead of a flat format. In a hierarchical format, columns contain specific information about all possible units of analysis and rows form the individual observations (households, establishments, products, communities/countries, or any combination of those). In a flat format, multiple columns contain the same information but on different units of analysis. Hierarchical files are easier to analyse, as they contain fewer columns that store the same information and are more compact. Hierarchical files are also easier to manage and document as the number of variables is smaller, and the same variable-level metadata would not have to be repeated for many variables. 

2. Unique record identifiers

Each distinct observation in a data file (for example, each household, each individual, or each facility) must have a unique identifier (or "key"). This identifier can be a single variable, or a combination of variables. The ID variable or the variables included in a combination that form a key variable cannot have missing values.

ID variables are typically generated by the data entry software application. ID variables should not contain spaces, special characters, or accentuated characters, since they may suffer modifications when the dataset is converted in different formats. For the convenience of users of the data, avoid identifiers consisting of a combination of too many variables. If you prepare your data files for public dissemination, it may be preferable to generate unique identifiers that would not be a compilation of geographic codes as geographic codes are highly identifying. 

It is important also to confirm that the unique identifier variable (or combination of variables) truly does identify each record uniquely. All statistical packages provide commands to run such verification (see for example the *duplicate* function in SPSS, or the *isid* command in Stata). The Metadata Editor provides a tool to verify that a variable or combination of variables provides a unique identifier, but it does not provide a solution to fix possible issues. It is thus recommended to run these checks prior to documenting your data files in the Metadata Editor. 

3. Relationships between data files

A dataset is often composed of multiple data files with relationship. For example, a household survey will have data files containing variables at the household level (dwelling characteristics, assets ownership, etc.) and other files containing variables at the individual (household member) level (age, sex, marital status, etc.) The unique identifiers or key variable(s) of each data file are used to establish the relationships, i.e. to merge data files. Use statistical software to validate that data files can be merge as relevant. For a household survey, for example, verify that all records in the individual-level files have a corresponding household in the household-level master file. Also, verify that all households have at least on e corresponding record in the household-roster file that lists all individuals. 

4. Consistency in variable names

Make sure that when a same variable is included in more than one data file of a same dataset, it has the same name in all data files where it appears. If the variable is different in any way, the variable name must be different. For example, if a data file contains variable AGE in a data file and the same variable, but with a different coding or edited in another data file, these variables must be given different names. Variables that are exactly similar must have the same name; variables that differ in any way must be named differently.

5. Missing values

Getting data ready for documentation also involves checking for variables that do not provide complete information because they contain many missing values. Missing values can have unexpected effects on the data analysis process. 

6. Value ranges

Generate descriptive statistics for all variables (frequencies for discrete variables; min/max/mean for continuous variables) and verify that these statistics look reasonable. Some variables must take on only specific values, such as code “1” or “2” for SEX, or a positive integer up to a reasonnable limit (99) for AGE. Values for categorical variables should be guided by the questionnaire or separate documentation for constructed variables. 

7. Number of records in each data file

Check that the number of observations in each data file corresponds to what is expected. Make sure that in all the files, the number of records is the same as (or is similar to) what is explicitly stated in the sample design of your survey, or is as reported in survey reports. 

8. Completeness

Verify the completeness of your data files by comparing the content of these files with the survey questionnaire. All variables in the questionnaire should appear in the dataset, except those excluded on purpose by the producer of the data because of reasons of confidentiality or quality. It is a good practice to order variables in the data files as they are in the questionnaire. This practice will help users navigate seamlessly across the dataset using the questionnaire as a route map. Verify also that all relevant derived (calculated or imputed) variables are in the data files.

9. Sample weights

Include the relevant weighting coefficients and variables identifying the stratification levels in the data files. All data files of a sample survey should have clearly labelled variable(s) with information on the survey weights. A detailed description of how the survey weights are calculated should be provided in the documentation of the survey. Based on it, you can perform some basic range checks. Additionally, for sample surveys, verify that the variables identifying the various levels of stratification and the primary sampling unit are included and easily identifiable in at least one of the data files. These variables are needed for the calculation of sampling errors.

10. Variable labels

Variable labels should be short and precise. They should provide a clear indication of what information is contained in the variables. Variable labels are brief descriptions or attributes of each variable. Without variable labels, users are not able to link the variables in the database to the questions of the questionnaire. So, one should ensure that all variables are labelled. Variable labels should be informative, short and accurate. The same label should not be used for two different variables. Although it is common practice to use the literal question from a survey as variable label, literal questions are often longer than the maximum number of characters, so this is not an advisable practice. Variable labels can be added or edited in the Metadata Editor.

11. Value labels

Value labels are used for categorical variables. ALl codes used in categorical variables should have a clear, short label. Value labels can be added or edited in the Metadata Editor.

12. Non-relevant variables

Remove all unnecessary or temporary variables that present no interest for users from the data files. 

13. Data types

Check that the data types are correct, and optimize the variable format. Do not include string variables if they can be converted into numeric variables. Look at your data and check each variable type, particularly for those that you expect to be numeric (age, years, number of persons/employees/hours, income, purchases/expenditures, weights, and so forth). If there are numeric variables stored as string variables, convert them using a statistical package before you start documenting your dataset.

14. Privacy protection

Datasets intended for dissemination should in general not contain any directed identifiers. Verify that sensitive information or direct identifiers that could reveal the identity of the respondent directly (names, addresses, GPS coordinates, phone numbers, etc.) have been removed from the data files. Remember to preserve an unaltered copy of all your files before making any suppression of information.

15. Compress your files

Statistical software like Stata provide a "compress" or equivalent function to optimize the storage of the data. This function adjusts the format of the variable to reduce the size of the data file without loss of precision or information. 

## Creating a new project

A *project* consists of a survey, a census, or another type of activity that generates microdata). To create a new project, click on "Create new project" in the Project page and, when prompted, select "Microdata" as data type.

![image](https://user-images.githubusercontent.com/35276300/214939118-1c290c3b-52c2-4f05-88ac-31952c04e668.png)

![image](https://user-images.githubusercontent.com/35276300/214939280-12042a85-4fc1-4f9e-acdf-261553b202cb.png)

A new project home page will be displayed. 

![image](https://user-images.githubusercontent.com/35276300/214939548-3cc62a96-c7f4-4c6b-a29d-cfd914c79abd.png)

The template identified  the Template Manager as the default template for Microdata in will be used. You can select a different template by clicking on "Switch template". 

![image](https://user-images.githubusercontent.com/35276300/214939822-f513121c-b659-45d1-bb7b-45a0243d471b.png)

The navigation bar on the right of the page reflects the content of the template you selected. Note that you may change the template at any time without losing any information. The templates are only "masks" used to generate the metadata entry forms in the Metadata Editor.

![image](https://user-images.githubusercontent.com/35276300/214939873-1a6bfb5f-da4f-4824-94cc-9677e2066f49.png)

The project home page provides an option to select a project thumbnail. It can for example be the logo of your survey or census. The thumbnail will be used by the NADA cataloguing application. It will also be displayed in the Metadata Home page. The thumbnail is an image in JPG or PNG format. 

![image](https://user-images.githubusercontent.com/35276300/214940035-d99d65fe-7764-45b7-b498-d367d52c98c5.png)

To select a thumbnail, click on "Change image" and select an image file.

![image](https://user-images.githubusercontent.com/35276300/214941199-bb5fd48d-47dc-4638-a355-9e068da77279.png)

![image](https://user-images.githubusercontent.com/35276300/214941280-2493b610-1c2b-4c25-b8e5-37c07d1c6dde.png)

### Document description and Study description

The navigation tree in the left frame allows you to navigate the metadata entry pages. The metadata can be entered in any sequence. 

Fill out the sections **Document description** and **Study description** sections. Try and provide as much and as relevant information in all relevant metadata elements.

![image](https://user-images.githubusercontent.com/35276300/214941497-887f698d-e763-48fe-8297-0e45bf6d2f73.png)

A description of the content of each element is available by clicking on the "?". You will find more information on the metadata elements in the Schemna Guide (https://ihsn.github.io/editor/#/template-manager/microdata).

If the content you enter violates a validation rule entered in the template, an error message will be displayed in red. All violation of rules will also be displayed in the project Home page. 

The *Required* elements are indicated by a red asterisk. 

![image](https://user-images.githubusercontent.com/35276300/214941921-3e765962-8573-486c-af2c-a2168e79ebf2.png)

When an element is "repeatable", an option to "Add rows" is provided.

![image](https://user-images.githubusercontent.com/35276300/214942382-a69a9dab-2410-4493-8b1e-8d2469b14868.png)

When a controlled vocabulary has been entered in the template, a drop down menu will appear.

![image](https://user-images.githubusercontent.com/35276300/214942534-d47df5a3-93f0-4d61-b956-46bbc89f0632.png)

Importing metadata: 


### Importing data files

If you have data files available in CSV, Stata (.dta), or SPSS (.sav) format, you can import the data to automatically populate some of the content of the *File description* section and much of the content of the *Variable description* section. The Metadata Editor relies on the R software and on the Haven library to import (and export) data files. 

When a data file is imported, the application will:
- Generate the list of variables for each data file
- Import the variable and value labels from the data files (if the data have been labelled in Stata or SPSS)
- Generate summary statistics for each variable, which may be saved as metadata.

To import data files, select "Data files" in the navigation bar, and click "Import files".

![image](https://user-images.githubusercontent.com/35276300/214943689-7c608a52-777c-41c2-9662-d1c66797e370.png)

Select the data files you want to import.

![image](https://user-images.githubusercontent.com/35276300/214944454-86919d0a-e0ae-40dd-a537-a94122afa4b3.png)
![image](https://user-images.githubusercontent.com/35276300/214952350-92cf2cdd-371c-4a4e-8fda-08653a4cb5b3.png)

Success
![image](https://user-images.githubusercontent.com/35276300/214952439-00f9a702-16a9-4b82-8bb1-690d68aaf966.png)

### Creating data files

In some cases, you may want to document data files that you do not have. In such case, you will not be able to automatically generate the data dictionary. But you can enter it manually.
...

### File description

Enter a brief description of each file by select the filename in the navigation bar, and filling out the metadata entry form. Then save.
![image](https://user-images.githubusercontent.com/35276300/214966052-85ffabc6-7d04-4ca3-b3c0-800c44499b68.png)

### Preview data

You can preview the data you imported by selecting *Data* in the navigation bar for one of the imported data files. The data can be viewed and exported. The Metadata Editor does not provide an option to modify the data.

![image](https://user-images.githubusercontent.com/35276300/214965888-3af24fa2-8fa4-4d3a-a225-bc90f62130a8.png)

### Variable description and statistics

For each data file, the Variables section shows a variable list and metadata. Additional metadata can be entered for each variable.
![image](https://user-images.githubusercontent.com/35276300/214965734-f5d357e0-af79-4d08-9f12-1025adccf605.png)
What has been imported from the data files:
- List of variables with name, label and type ("Variables" block).
- Value labels for categorical variables ("Categories" block).
- Variable information: type, decimals, format, missing values
- Variable type:

Editing metadata:

- Changing file names:
- Changing variable type:
- Adding or editing variable labels:
- Deleting variables:
- Editing value labels:
- Adding value labels: 
   Categories can be added or edited. 
   - Generate categories from statistics button:
   - Copy / paste
   - Store in repository

Documentation:
- Summary statistics
- Weights
- Documentation
![image](https://user-images.githubusercontent.com/35276300/214967059-352ab9cf-4dde-4867-85fe-dd40ba0bdbc6.png)

In the variable page: Description
- Ctrl and Shift keys
- Spreading metadata
- Importing metadata
- Copy/paste

- JSON

Weights

Keys

### Variable groups

### Tags

### External resources

![image](https://user-images.githubusercontent.com/35276300/214945692-0e3a37e5-14b0-495c-8eeb-351d305fb185.png)

### Saving and exporting metadata

### Exporting data

### Diagnostics

## Editing an existing project

Open and edit
Replacing data files

## Using DDI from external applications

Use case: CsPro or Survey Solutions.
Data files not necessarily the exact same (variables may have been created, dropped, modified)
But much to re-use.
"Import metadata" tool.

## Migrating Nesstar files

Manual:

Batch: For Windows users only. Can automate the export. 






